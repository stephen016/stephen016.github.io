---
title: "Privacy-Preserving Soft Prompt Transfer (POST)"
excerpt: "Efficient and privacy-preserving framework for transferring soft prompts between large language models with differential privacy guarantees"
collection: portfolio
---

<h2>Privacy-Preserving Soft Prompt Transfer (POST)</h2>

<p><strong>Secure Knowledge Transfer for Large Language Models</strong></p>

<h3>Overview</h3>
<p>POST introduces the first framework for transferring soft prompts between different LLMs while maintaining formal privacy guarantees through differential privacy mechanisms. This breakthrough enables secure collaboration and knowledge sharing in LLM deployments.</p>

<h3>Key Innovations</h3>
<ul>
<li><strong>Differential Privacy Integration</strong>: Formal privacy guarantees with ε-differential privacy (ε < 1.0)</li>
<li><strong>Cross-Model Transfer</strong>: Works across different LLM architectures (GPT, LLaMA, T5)</li>
<li><strong>Efficiency Optimization</strong>: 10x faster than traditional fine-tuning approaches</li>
<li><strong>Knowledge Distillation</strong>: Advanced techniques for compressing and transferring prompt knowledge</li>
</ul>

<h3>Technical Approach</h3>
<ul>
<li><strong>Privacy-Preserving Extraction</strong>: Extracts transferable knowledge with calibrated noise injection</li>
<li><strong>Embedding Compression</strong>: Compresses soft prompt representations while preserving utility</li>
<li><strong>Adaptive Fine-tuning</strong>: Efficient adaptation to target LLMs with minimal overhead</li>
</ul>

<h3>Impact & Applications</h3>
<ul>
<li><strong>Federated Learning</strong>: Enables secure collaboration between organizations</li>
<li><strong>Model Deployment</strong>: Facilitates privacy-conscious AI development</li>
<li><strong>Research Collaboration</strong>: Allows sharing of prompt engineering advances safely</li>
</ul>

<h3>Results</h3>
<ul>
<li>Maintains 95%+ performance on downstream tasks</li>
<li>Strong privacy guarantees with theoretical foundations</li>
<li>Successful transfer across multiple model families</li>
<li>Accepted at ICML 2025</li>
</ul>

<p><a href="https://www.arxiv.org/pdf/2506.16196"><strong>Paper</strong></a> | <a href="../POST.html"><strong>Project Page</strong></a></p> 
