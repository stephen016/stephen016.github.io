
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Structurally Prune Anything: Any Architecture, Any Framework, Any Time">
  <meta name="keywords" content="SPA">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SPA</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');



  </script> -->

<!-- <link rel="icon" type="image/png" href="media/nice-slam/like.png">  -->
<link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./projects/css/bulma.min.css">
  <link rel="stylesheet" href="./projects/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./projects/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./projects/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./projects/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./projects/js/fontawesome.all.min.js"></script>
  <script src="./projects/js/bulma-carousel.min.js"></script>
  <script src="./projects/js/bulma-slider.min.js"></script>
  <script src="./projectsjs/index.js"></script>
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      }
    };
    </script>
    <script id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://stephen016.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://stephen016.github.io/SPA">
            SPA - arxiv 2024
          </a>
          <a class="navbar-item" href="https://stephen016.github.io/POST">
            POST - ICML 2025
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- <div class="columns is-centered">
        <div class="column is-7 has-text-centered">
          <img src="media/nice-slam/nice-slam-logo2.png" alt="NICE-SLAM"/>
        </div>
      </div> -->
        <div class="column has-text-centered">
          <!-- <h1 class="title is-1 publication-title"><img src="media/nice-slam/like.png" width="90">NICE-SLAM&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>Neural Implicit Scalable Encoding for SLAM</h1> -->
          <h1 class="title is-2 publication-title">Structurally Prune Anything: Any Architecture, Any Framework, Any Time</h1>
          <div class="column is-full_width">
            <!-- <h2 class="title is-5">IEEE International Symposium on Mixed and Augmented Reality (ISMAR) 2023</h2> -->
          </div>
          <!-- <br> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
                <a href="https://stephen016.github.io/">Xun Wang</a><sup>1 * #</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/john-rachwan/">John Rachwan</a><sup>2 *</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
                <span class="author-block">
                <a href="https://www.cs.cit.tum.de/daml/guennemann/">Stephan GÃ¼nnemann</a><sup>2,3</sup>&nbsp;&nbsp;&nbsp;&nbsp;
              </span>
              <span class="author-block">
                <a href="https://sharpenb.github.io/">Bertrand Charpentier</a><sup>2,3</sup>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
              </span>
            </div>
            <div class="column is-full_width">
              <h2 class="is-size-6">* Equal Contribution</h2>
              <h2 class="is-size-6"># work was done at Technical University of Munich </h2>

            <!-- <h2 class="is-size-6">(* equal contribution)  (<span>&#8224;</span> corresponding author)</h2> -->
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>CISPA Helmholtz Center for Information Security</span>&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>Pruna AI </span>
            <br>
            <span class="author-block"><sup>3</sup>Department of Computer Science & Munich Data Science Institute, Technical University of Munich </span>&nbsp;&nbsp;

          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2403.18955" target="_blank"
                   class="button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=qn35joS5zZM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Poster Link. -->
              <!-- <span class="link-block">
                <a href="media/nice-slam/poster_nice-slam.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-palette"></i>
                  </span>
                  <span>Poster</span>
                  </a>
              </span> -->
              <!-- Code Link. -->
               <!-- <span class="link-block">
               <a href="https://github.com/yingyexin/SimpleMapping" target="_blank"
		   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span >Code</span>
                  </a>
              </span>
            </div> -->

          </div>
        </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
        <!-- Paper video. -->

        <!--/ Paper video. -->

    <br>
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Neural network pruning serves as a critical technique for enhancing the efficiency of deep learning models. 
            Unlike unstructured pruning, which only sets specific parameters to zero, structured pruning eliminates entire channels, 
            thus yielding direct computational and storage benefits. However, the diverse patterns for coupling parameters, 
            such as residual connections and group convolutions, the diverse deep learning frameworks, 
            and the various time stages at which pruning can be performed make existing pruning methods less adaptable to different architectures,
            frameworks, and pruning criteria. To address this, we introduce Structurally Prune
            Anything (SPA), a versatile structured pruning framework that can prune neural networks with any architecture, from any framework, and at any stage of training. SPA
            leverages a standardized computational graph and ONNX representation to prune
            diverse neural network architectures without the need for manual intervention. SPA
            employs a group-level importance estimation method, which groups dependent
            computational operators, estimates their importance, and prunes unimportant coupled channels. This enables the transfer of various existing pruning criteria into a
            structured group style. As a result, SPA supports pruning at any time, either before
            training, after training with fine-tuning, or after training without fine-tuning. In the
            context of the latter, we introduce Optimal Brain SPA (OBSPA), an algorithm that
            achieves state-of-the-art pruning results needing neither fine-tuning nor calibration
            data. In extensive experiments, SPA shows competitive to state-of-the-art pruning
            performance across various architectures, from popular frameworks, at different
            pruning times.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full_width">
        <hr>
        <h2 class="title is-3">Method</h2>
        <br>
        <img src="projects/SPA/System_overview.png" class="center"/>
        <div class="content has-text-justified">
          <br>  
          <p>
            System overview of <strong>SPA</strong>. The source model can be chosen freely from different frameworks with different structures, either trained or not. A computational graph is built to store the dependency information between operators and data. The pruning procedure consists of four steps: coupling channels, grouping channels \& importance estimation, and pruning. After pruning, the pruned model can be converted to other frameworks for further usage.
          </p>
        </div>
      </div>
    </div>
    <hr>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{wang2024structurallypruneanythingarchitecture,
        title={Structurally Prune Anything: Any Architecture, Any Framework, Any Time}, 
        author={Xun Wang and John Rachwan and Stephan GÃ¼nnemann and Bertrand Charpentier},
        year={2024},
        eprint={2403.18955},
        archivePrefix={arXiv},
        primaryClass={cs.LG},
        url={https://arxiv.org/abs/2403.18955}, 
  }</code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
          </p>
        </div>
      </div>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
